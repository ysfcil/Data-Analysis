{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"loan_data.csv\")\n",
    "df.info()\n",
    "df.fillna(value=df.mean(), inplace=True)\n",
    "df[\"Gender\"].fillna(value=\"Unknown\", inplace=True)\n",
    "df[\"Self_Employed\"].fillna(value=\"Unknown\", inplace=True)\n",
    "df[\"Married\"].fillna(value=\"Unknown\", inplace=True)\n",
    "df[\"Dependents\"].fillna(value=\"Unknown\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_params = {\n",
    "     \n",
    "        'ridge': {\n",
    "            'model': RidgeClassifierCV(),\n",
    "            'params': {\n",
    "                'alphas': [1,2],\n",
    "            }\n",
    "        },\n",
    "        \"xgbclassifier\":\n",
    "        {\n",
    "            \"model\": XGBClassifier(),\n",
    "            \"params\": \n",
    "            {\n",
    "                'min_child_weight': [1, 5],\n",
    "        'gamma': [0.5, 1],\n",
    "        'subsample': [0.6, 1.0],\n",
    "        'colsample_bytree': [0.6],\n",
    "        'max_depth': [3, 4]\n",
    "            }\n",
    "        },\n",
    "        \"decisionTree\":\n",
    "        {\n",
    "            \"model\": DecisionTreeClassifier(),\n",
    "            \"params\":\n",
    "            {\n",
    "                \"criterion\": ['gini', 'entropy'],\n",
    "                \"max_depth\" : [2,4,6,8,10,12]\n",
    "            }\n",
    "        },\n",
    "        \"random_forrest\":\n",
    "        {\n",
    "            \"model\": RandomForestClassifier(),\n",
    "            \"params\":\n",
    "            {\n",
    "                \"n_estimators\": [int(x) for x in np.linspace(start = 200, stop = 1000, num = 10)],\n",
    "                \"min_samples_split\": [2, 5, 10],\n",
    "                \"bootstrap\":  [True, False]\n",
    "            }\n",
    "        },\n",
    "        \"svc\":\n",
    "        {\n",
    "            \"model\": SVC(),\n",
    "            \"params\":\n",
    "            {\n",
    "                \"kernel\": ['poly', 'rbf', 'sigmoid'],\n",
    "                \"C\": [50, 10, 1.0, 0.1, 0.01]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import recall_score\n",
    "scores = []\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "for model_name, mp in model_params.items():\n",
    "    clf =  RandomizedSearchCV(mp['model'], mp['params'], cv=cv, return_train_score=False, n_iter=50, scoring=recall_score)\n",
    "    clf.fit(x_train, y_train)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    \n",
    "df_2 = pd.DataFrame(scores,columns=['model','best_score','best_params', \"best_recall\"])\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "y_test.value_counts()\n",
    "sns.heatmap(confusion_matrix(y_pred=y_pred, y_true=y_test), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for f in numerical_features:\n",
    "    fig, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (0.15, 0.85)})\n",
    "    ax_box.grid(alpha=0.75)\n",
    "    ax_hist.grid(alpha=0.75)\n",
    "    flierprops = dict(\n",
    "        markerfacecolor=\"r\", markersize=2, linestyle=\"none\", markeredgecolor=\"r\"\n",
    "    )\n",
    "    sb.boxplot(df[f], orient=\"h\", ax=ax_box, flierprops=flierprops)\n",
    "    sb.histplot(df[f], ax=ax_hist, bins=50, kde=True)\n",
    "\n",
    "    # Remove x axis name for the boxplot\n",
    "    ax_box.set(xlabel=\"\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outlier detection:\n",
    "print(len(df))\n",
    "for f in numerical_features:\n",
    "    q1 = df[f].quantile(0.25)\n",
    "    q3 = df[f].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    upper_limit = q3 + iqr *1.5\n",
    "    lower_limit = q1 - iqr *1.5\n",
    "    new_df = df.loc[((df[f]<upper_limit) & (df[f]>lower_limit))]\n",
    "print(len(new_df), len(df)-len(new_df))\n",
    "df = new_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
