{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "X = fetch_california_housing()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X.data, X.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8103 - root_mean_squared_error: 0.9002 - val_loss: 0.3706 - val_root_mean_squared_error: 0.6088\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3698 - root_mean_squared_error: 0.6081 - val_loss: 3.0228 - val_root_mean_squared_error: 1.7386\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3733 - root_mean_squared_error: 0.6110 - val_loss: 0.3234 - val_root_mean_squared_error: 0.5687\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3391 - root_mean_squared_error: 0.5823 - val_loss: 0.7871 - val_root_mean_squared_error: 0.8872\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3261 - root_mean_squared_error: 0.5711 - val_loss: 1.3328 - val_root_mean_squared_error: 1.1545\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3242 - root_mean_squared_error: 0.5694 - val_loss: 0.5469 - val_root_mean_squared_error: 0.7396\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3100 - root_mean_squared_error: 0.5568 - val_loss: 1.3368 - val_root_mean_squared_error: 1.1562\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3024 - root_mean_squared_error: 0.5499 - val_loss: 1.0036 - val_root_mean_squared_error: 1.0018\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3043 - root_mean_squared_error: 0.5516 - val_loss: 0.2907 - val_root_mean_squared_error: 0.5392\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2902 - root_mean_squared_error: 0.5387 - val_loss: 0.5809 - val_root_mean_squared_error: 0.7622\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2863 - root_mean_squared_error: 0.5351 - val_loss: 0.2695 - val_root_mean_squared_error: 0.5191\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2908 - root_mean_squared_error: 0.5393 - val_loss: 0.5450 - val_root_mean_squared_error: 0.7383\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2845 - root_mean_squared_error: 0.5334 - val_loss: 0.3054 - val_root_mean_squared_error: 0.5526\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2822 - root_mean_squared_error: 0.5313 - val_loss: 0.3846 - val_root_mean_squared_error: 0.6202\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2801 - root_mean_squared_error: 0.5292 - val_loss: 1.4469 - val_root_mean_squared_error: 1.2029\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2830 - root_mean_squared_error: 0.5320 - val_loss: 0.3961 - val_root_mean_squared_error: 0.6294\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2755 - root_mean_squared_error: 0.5249 - val_loss: 0.9482 - val_root_mean_squared_error: 0.9738\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2710 - root_mean_squared_error: 0.5206 - val_loss: 0.4095 - val_root_mean_squared_error: 0.6399\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2679 - root_mean_squared_error: 0.5176 - val_loss: 0.3601 - val_root_mean_squared_error: 0.6000\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2683 - root_mean_squared_error: 0.5180 - val_loss: 0.3253 - val_root_mean_squared_error: 0.5704\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2623 - root_mean_squared_error: 0.5122 - val_loss: 0.3070 - val_root_mean_squared_error: 0.5541\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2579 - root_mean_squared_error: 0.5079 - val_loss: 0.2703 - val_root_mean_squared_error: 0.5200\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2532 - root_mean_squared_error: 0.5032 - val_loss: 0.3028 - val_root_mean_squared_error: 0.5503\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2676 - root_mean_squared_error: 0.5173 - val_loss: 0.6479 - val_root_mean_squared_error: 0.8050\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2565 - root_mean_squared_error: 0.5065 - val_loss: 0.2881 - val_root_mean_squared_error: 0.5368\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2486 - root_mean_squared_error: 0.4986 - val_loss: 0.7871 - val_root_mean_squared_error: 0.8872\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2497 - root_mean_squared_error: 0.4997 - val_loss: 0.3271 - val_root_mean_squared_error: 0.5719\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2498 - root_mean_squared_error: 0.4998 - val_loss: 0.3038 - val_root_mean_squared_error: 0.5512\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2474 - root_mean_squared_error: 0.4974 - val_loss: 0.2556 - val_root_mean_squared_error: 0.5055\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2409 - root_mean_squared_error: 0.4908 - val_loss: 0.4409 - val_root_mean_squared_error: 0.6640\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.2811 - root_mean_squared_error: 0.5301\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "121/121 [==============================] - 0s 925us/step - loss: 0.4409 - root_mean_squared_error: 0.6640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44087955355644226, 0.6639876365661621]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "model = tf.keras.Sequential([\n",
    "norm_layer,\n",
    "tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "tf.keras.layers.Dense(1)\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "norm_layer.adapt(X_train)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "validation_data=(X_valid, y_valid))\n",
    "mse_test, rmse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "model.evaluate(X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "def build_model(hp):\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=8, default=2)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2,\n",
    "    sampling=\"log\")\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "        metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
